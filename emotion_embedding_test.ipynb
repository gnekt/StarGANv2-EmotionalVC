{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwaQq4GRU_Nw"
      },
      "source": [
        "# Emotion Embedding Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCpoXuZeGKAn"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3on9IjGhVGTP"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import random\n",
        "import yaml\n",
        "from munch import Munch\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import librosa\n",
        "import pandas as pd\n",
        "from models import EmotionEncoder\n",
        "\n",
        "DEVICE = \"cuda\"\n",
        "DATA_PATH = \"Data/emotion_embedding_test_file.txt\"\n",
        "DATA_HEADER = [\"file_path\",\"emotion_id\"]\n",
        "DATA_SEPARETOR = \"|\"\n",
        "MODEL_PATH = \"Models/Experiment-3\"\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4SFZgbD4FiHY"
      },
      "outputs": [],
      "source": [
        "to_mel = torchaudio.transforms.MelSpectrogram(\n",
        "    n_mels=80, n_fft=2048, win_length=1200, hop_length=300)\n",
        "mean, std = -4, 4\n",
        "\n",
        "def preprocess(wave):\n",
        "    wave_tensor = torch.from_numpy(wave).float()\n",
        "    mel_tensor = to_mel(wave_tensor)\n",
        "    mel_tensor = (torch.log(1e-5 + mel_tensor.unsqueeze(0)) - mean) / std\n",
        "    return mel_tensor\n",
        "\n",
        "def build_model(model_params={}):\n",
        "    args = Munch(model_params)\n",
        "    emotion_encoder = EmotionEncoder(args.dim_in, args.style_dim, args.num_domains, args.max_conv_dim)\n",
        "    return Munch(emotion_encoder=emotion_encoder)\n",
        "\n",
        "def compute_style(speaker_dicts):\n",
        "    reference_embeddings = []\n",
        "    for key, (path, speaker) in speaker_dicts.items():\n",
        "        wave, sr = librosa.load(path, sr=24000)\n",
        "        audio, index = librosa.effects.trim(wave, top_db=30)\n",
        "        if sr != 24000:\n",
        "            wave = librosa.resample(wave, sr, 24000)\n",
        "        mel_tensor = torch.zeros((1,80,400))\n",
        "        mel = preprocess(wave).to(DEVICE)\n",
        "        mel_tensor[0,:,:mel.shape[2]] = mel\n",
        "        with torch.no_grad():\n",
        "            label = torch.LongTensor([speaker]).to(\"cuda\")\n",
        "            ref = starganv2.emotion_encoder(mel_tensor.to(\"cuda\"), label)\n",
        "        reference_embeddings.append(ref)\n",
        "    \n",
        "    return reference_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMWjcdaVFiHZ"
      },
      "source": [
        "### Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ou4367LCyefA"
      },
      "outputs": [],
      "source": [
        "# load starganv2\n",
        "\n",
        "with open(f'{MODEL_PATH}/config.yml') as f:\n",
        "    starganv2_config = yaml.safe_load(f)\n",
        "starganv2 = build_model(model_params=starganv2_config[\"model_params\"])\n",
        "params = torch.load(f\"{MODEL_PATH}/ex_3_epoch.pth\", map_location=DEVICE)\n",
        "params = params['model_ema']\n",
        "_ = [starganv2[key].load_state_dict(params[key]) for key in starganv2 if key == \"style_encoder\"]\n",
        "_ = [starganv2[key].eval() for key in starganv2 if key == \"style_encoder\"]\n",
        "starganv2.emotion_encoder = starganv2.emotion_encoder.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KvrzOfuFiHc"
      },
      "source": [
        "#### Convert by style encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uf5t5_pIFiHc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# with reference, using style encoder\n",
        "dataframe = pd.read_csv(DATA_PATH, sep=DATA_SEPARETOR, names=DATA_HEADER)\n",
        "emotion_dict ={}\n",
        "speaker_dicts = {}\n",
        "for index,speaker_emotion in dataframe.groupby(\"emotion_id\"):\n",
        "    speaker_dicts={}\n",
        "    for index, row in speaker_emotion.iterrows():\n",
        "        speaker_dicts[index] = (row[\"file_path\"], row[\"emotion_id\"])\n",
        "    emotion_dict[speaker_emotion.iloc[0].emotion_id] = speaker_dicts\n",
        "\n",
        "emotion_embeddings = {}\n",
        "embeddings = []\n",
        "for emotion_idx, data in emotion_dict.items():\n",
        "    _temp_result=compute_style(data)\n",
        "    emotion_embeddings[emotion_idx]=_temp_result\n",
        "    embeddings += _temp_result\n",
        "\n",
        "embeddings = [embedding.to(\"cpu\").squeeze(0).tolist() for embedding in embeddings]\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "pca = PCA(2)\n",
        "df = pca.fit_transform(embeddings)\n",
        "df = pd.DataFrame(df, columns=[\"x_repr\",\"y_repr\"])\n",
        "dataframe = pd.concat([dataframe,df], axis=1)\n",
        "sns.scatterplot(data=dataframe, x=\"x_repr\", y=\"y_repr\", hue=\"emotion_id\", palette=\"deep\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SWh3o9hvGvJt"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('stargan')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "af3ab013e161d7e2071e405d816695dd1dca74efb3c18ca57ddcf9213a3f1219"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
