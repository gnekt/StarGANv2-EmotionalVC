{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd StarGANv2-EmotionalVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install SoundFile munch parallel_wavegan pydub pyyaml click librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import click\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from functools import reduce\n",
    "from munch import Munch\n",
    "\n",
    "from meldataset import build_dataloader\n",
    "from optimizers import build_optimizer\n",
    "from models import build_model\n",
    "from trainer import Trainer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from Utils.ASR.models import ASRCNN\n",
    "from Utils.JDC.model import JDCNet\n",
    "\n",
    "import logging\n",
    "from logging import StreamHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True #\n",
    "\n",
    "def main(config_path):\n",
    "    config = yaml.safe_load(open(config_path))\n",
    "    print(config)\n",
    "    log_dir = config['log_dir']\n",
    "    if not osp.exists(log_dir): os.makedirs(log_dir, exist_ok=True)\n",
    "    shutil.copy(config_path, osp.join(log_dir, osp.basename(config_path)))\n",
    "    writer = SummaryWriter(log_dir + \"/tensorboard\")\n",
    "\n",
    "    # write logs\n",
    "    file_handler = logging.FileHandler(osp.join(log_dir, 'train.log'))\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(logging.Formatter('%(levelname)s:%(asctime)s: %(message)s'))\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    ### Get configuration\n",
    "    batch_size = config.get('batch_size', 2)\n",
    "    device = config.get('device', 'cpu')\n",
    "    epochs = config.get('epochs', 1000)\n",
    "    save_freq = config.get('save_freq', 20)\n",
    "    dataset_configuration = config.get('dataset_configuration', None)\n",
    "    stage = config.get('stage', 'star')\n",
    "    fp16_run = config.get('fp16_run', False)\n",
    "    ###\n",
    "    \n",
    "    train_set_path = \"./Data/training_list.txt\"\n",
    "    validation_set_path = \"./Data/validation_list.txt\"\n",
    "    # load dataloader \n",
    "    train_dataloader = build_dataloader(train_set_path,dataset_configuration,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_workers=2,\n",
    "                                        device=device)\n",
    "    \n",
    "    val_dataloader = build_dataloader(validation_set_path,dataset_configuration,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_workers=2,\n",
    "                                        device=device)\n",
    "\n",
    "    # load pretrained ASR model, FROZEN\n",
    "    ASR_config = config.get('ASR_config', False)\n",
    "    ASR_path = config.get('ASR_path', False)\n",
    "    with open(ASR_config) as f:\n",
    "            ASR_config = yaml.safe_load(f)\n",
    "    ASR_model_config = ASR_config['model_params']\n",
    "    ASR_model = ASRCNN(**ASR_model_config)\n",
    "    params = torch.load(ASR_path, map_location='cpu')['model']\n",
    "    ASR_model.load_state_dict(params)\n",
    "    _ = ASR_model.eval()    \n",
    "    \n",
    "    # load pretrained F0 model\n",
    "    F0_path = config.get('F0_path', False)\n",
    "    F0_model = JDCNet(num_class=1, seq_len=192)\n",
    "    params = torch.load(F0_path, map_location='cpu')['net']\n",
    "    F0_model.load_state_dict(params)\n",
    "    \n",
    "    # build model\n",
    "    model, model_ema = build_model(Munch(config['model_params']), F0_model, ASR_model)\n",
    "\n",
    "    scheduler_params = {\n",
    "        \"max_lr\": float(config['optimizer_params'].get('lr', 2e-4)),\n",
    "        \"pct_start\": float(config['optimizer_params'].get('pct_start', 0.0)),\n",
    "        \"epochs\": epochs,\n",
    "        \"steps_per_epoch\": len(train_dataloader),\n",
    "    }\n",
    "    \n",
    "    _ = [model[key].to(device) for key in model]\n",
    "    _ = [model_ema[key].to(device) for key in model_ema]\n",
    "    scheduler_params_dict = {key: scheduler_params.copy() for key in model}\n",
    "    optimizer = build_optimizer({key: model[key].parameters() for key in model},\n",
    "                                      scheduler_params_dict=scheduler_params_dict)\n",
    "\n",
    "    trainer = Trainer(args=Munch(config['loss_params']), model=model,\n",
    "                            model_ema=model_ema,\n",
    "                            optimizer=optimizer,\n",
    "                            device=device,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            val_dataloader=val_dataloader,\n",
    "                            logger=logger,\n",
    "                            fp16_run=fp16_run)\n",
    "\n",
    "    if config.get('pretrained_model', '') != '':\n",
    "        trainer.load_checkpoint(config['pretrained_model'],\n",
    "                                load_only_params=config.get('load_only_params', True))\n",
    "\n",
    "    for _ in range(1, epochs+1):\n",
    "        epoch = trainer.epochs\n",
    "        train_results = trainer._train_epoch()\n",
    "        eval_results = trainer._eval_epoch()\n",
    "        results = train_results.copy()\n",
    "        results.update(eval_results)\n",
    "        logger.info('--- epoch %d ---' % epoch)\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, float):\n",
    "                logger.info('%-15s: %.4f' % (key, value))\n",
    "                writer.add_scalar(key, value, epoch)\n",
    "            else:\n",
    "                for v in value:\n",
    "                    writer.add_figure('eval_spec', v, epoch)\n",
    "        trainer.save_checkpoint(osp.join(log_dir, 'ex_3_c_backup.pth'))\n",
    "        if epoch in [50,100,149]:\n",
    "            trainer.save_checkpoint(osp.join(log_dir, f'ex_3_c_{epoch}.pth'))\n",
    "    return 0\n",
    "\n",
    "main(\"Configs/config.yml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('stargan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af3ab013e161d7e2071e405d816695dd1dca74efb3c18ca57ddcf9213a3f1219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
