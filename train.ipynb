{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mConfigs\u001b[0m/            \u001b[01;34mUtils\u001b[0m/          download.py    requirements.txt\n",
      "\u001b[01;34mData\u001b[0m/               \u001b[01;34m__pycache__\u001b[0m/    inference.py   train.ipynb\n",
      "\u001b[01;34mEnumeratorFactory\u001b[0m/  \u001b[01;34mdataset\u001b[0m/        losses.py      train.py\n",
      "LICENSE             dataset.zip     meldataset.py  trainer.py\n",
      "\u001b[01;34mModels\u001b[0m/             \u001b[01;34mdataset_maker\u001b[0m/  models.py      transforms.py\n",
      "README.md           download.ipynb  optimizers.py\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SoundFile\n",
      "  Downloading soundfile-0.11.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting parallel_wavegan\n",
      "  Downloading parallel_wavegan-0.5.5.tar.gz (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (5.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (8.1.3)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from SoundFile) (1.15.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from munch) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (1.12.0+cu116)\n",
      "Requirement already satisfied: setuptools>=38.5.1 in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (63.1.0)\n",
      "Collecting tensorboardX>=1.8\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (3.5.2)\n",
      "Requirement already satisfied: tqdm>=4.26.1 in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (4.64.0)\n",
      "Collecting kaldiio>=2.14.1\n",
      "  Downloading kaldiio-2.17.2.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (3.7.0)\n",
      "Collecting yq>=2.10.0\n",
      "  Downloading yq-3.1.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (4.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from parallel_wavegan) (3.7.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/dist-packages (from librosa) (5.1.1)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.8.1)\n",
      "Collecting numba>=0.45.1\n",
      "  Downloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->SoundFile) (2.21)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.1.0->parallel_wavegan) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.1.0->parallel_wavegan) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.1.0->parallel_wavegan) (4.34.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.1.0->parallel_wavegan) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.1.0->parallel_wavegan) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.1.0->parallel_wavegan) (2.8.2)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX>=1.8->parallel_wavegan) (3.19.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->parallel_wavegan) (4.3.0)\n",
      "Collecting toml>=0.10.0\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting xmltodict>=0.11.0\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting argcomplete>=1.8.1\n",
      "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown->parallel_wavegan) (4.11.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown->parallel_wavegan) (2.3.2.post1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.7.1)\n",
      "Building wheels for collected packages: parallel_wavegan, audioread, kaldiio\n",
      "  Building wheel for parallel_wavegan (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for parallel_wavegan: filename=parallel_wavegan-0.5.5-py3-none-any.whl size=72444 sha256=a9890f93be2b7056fefe1f455a59bef04c8cf9ed4a9f17e193f4ad5868172f95\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/52/22/a808b1f340ad33263b8998d6945d8013c7c4944ba0a7d5afc9\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23702 sha256=a66ca0bf2bc6bb33f228a83725b6dcd6b15c29bdf2c4054edbecfc0eb996c5a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/76/a4/cfb55573167a1f5bde7d7a348e95e509c64b2c3e8f921932c3\n",
      "  Building wheel for kaldiio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaldiio: filename=kaldiio-2.17.2-py3-none-any.whl size=24447 sha256=e4083b369729970db691f89d7de14c81c14b490477409ae154889ba2eeb2c547\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/8b/4e/17aac05e86a04db23f508115dc5aa24a6077fa5357eaee0d78\n",
      "Successfully built parallel_wavegan audioread kaldiio\n",
      "Installing collected packages: pydub, appdirs, xmltodict, toml, tensorboardX, munch, llvmlite, kaldiio, audioread, argcomplete, yq, SoundFile, pooch, numba, resampy, librosa, parallel_wavegan\n",
      "Successfully installed SoundFile-0.11.0 appdirs-1.4.4 argcomplete-2.0.0 audioread-3.0.0 kaldiio-2.17.2 librosa-0.9.2 llvmlite-0.39.1 munch-2.5.0 numba-0.56.4 parallel_wavegan-0.5.5 pooch-1.6.0 pydub-0.25.1 resampy-0.4.2 tensorboardX-2.5.1 toml-0.10.2 xmltodict-0.13.0 yq-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install SoundFile munch parallel_wavegan pydub pyyaml click librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import click\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from functools import reduce\n",
    "from munch import Munch\n",
    "\n",
    "from meldataset import build_dataloader\n",
    "from optimizers import build_optimizer\n",
    "from models import build_model\n",
    "from trainer import Trainer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from Utils.ASR.models import ASRCNN\n",
    "from Utils.JDC.model import JDCNet\n",
    "\n",
    "import logging\n",
    "from logging import StreamHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log_dir': 'Models/Experiment-2', 'save_freq': 10, 'device': 'cuda', 'epochs': 150, 'batch_size': 5, 'pretrained_model': '', 'load_only_params': False, 'fp16_run': True, 'dataset_configuration': {'data_separetor': '|', 'data_header': ['actor_id', 'statement_id', 'source_path', 'source_emotion', 'reference_path', 'reference_emotion']}, 'F0_path': 'Utils/JDC/bst.t7', 'ASR_config': 'Utils/ASR/config.yml', 'ASR_path': 'Utils/ASR/epoch_00100.pth', 'preprocess_params': {'sr': 24000, 'spect_params': {'n_fft': 2048, 'win_length': 1200, 'hop_length': 300}}, 'model_params': {'dim_in': 64, 'style_dim': 64, 'latent_dim': 16, 'num_domains': 4, 'max_conv_dim': 512, 'n_repeat': 4, 'w_hpf': 0, 'F0_channel': 256}, 'loss_params': {'g_loss': {'lambda_sty': 1.0, 'lambda_cyc': 5.0, 'lambda_ds': 1.0, 'lambda_norm': 1.0, 'lambda_asr': 10.0, 'lambda_f0': 5.0, 'lambda_f0_sty': 0.1, 'lambda_adv': 2.0, 'lambda_adv_cls': 0.5, 'norm_bias': 0.5}, 'd_loss': {'lambda_reg': 1.0, 'lambda_adv_cls': 0.1, 'lambda_con_reg': 10.0}, 'adv_cls_epoch': 50, 'con_reg_epoch': 30}, 'optimizer_params': {'lr': 0.0001}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "build_dataloader() got multiple values for argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             trainer\u001b[38;5;241m.\u001b[39msave_checkpoint(osp\u001b[38;5;241m.\u001b[39mjoin(log_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_\u001b[39m\u001b[38;5;132;01m%05d\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m epoch))\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 110\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConfigs/config.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m logger\u001b[38;5;241m.\u001b[39maddHandler(handler)\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(config_path):\n\u001b[1;32m     10\u001b[0m     config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(\u001b[38;5;28mopen\u001b[39m(config_path))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(config)\n",
      "\u001b[0;31mTypeError\u001b[0m: build_dataloader() got multiple values for argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True #\n",
    "\n",
    "def main(config_path):\n",
    "    config = yaml.safe_load(open(config_path))\n",
    "    print(config)\n",
    "    log_dir = config['log_dir']\n",
    "    if not osp.exists(log_dir): os.makedirs(log_dir, exist_ok=True)\n",
    "    shutil.copy(config_path, osp.join(log_dir, osp.basename(config_path)))\n",
    "    writer = SummaryWriter(log_dir + \"/tensorboard\")\n",
    "\n",
    "    # write logs\n",
    "    file_handler = logging.FileHandler(osp.join(log_dir, 'train.log'))\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(logging.Formatter('%(levelname)s:%(asctime)s: %(message)s'))\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    ### Get configuration\n",
    "    batch_size = config.get('batch_size', 2)\n",
    "    device = config.get('device', 'cpu')\n",
    "    epochs = config.get('epochs', 1000)\n",
    "    save_freq = config.get('save_freq', 20)\n",
    "    dataset_configuration = config.get('dataset_configuration', None)\n",
    "    stage = config.get('stage', 'star')\n",
    "    fp16_run = config.get('fp16_run', False)\n",
    "    ###\n",
    "    \n",
    "    train_set_path = \"./Data/training_list.txt\"\n",
    "    validation_set_path = \"./Data/validation_list.txt\"\n",
    "    # load dataloader \n",
    "    train_dataloader = build_dataloader(train_set_path,dataset_configuration,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_workers=2,\n",
    "                                        device=device)\n",
    "    \n",
    "    val_dataloader = build_dataloader(validation_set_path,dataset_configuration,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_workers=2,\n",
    "                                        device=device)\n",
    "\n",
    "    # load pretrained ASR model, FROZEN\n",
    "    ASR_config = config.get('ASR_config', False)\n",
    "    ASR_path = config.get('ASR_path', False)\n",
    "    with open(ASR_config) as f:\n",
    "            ASR_config = yaml.safe_load(f)\n",
    "    ASR_model_config = ASR_config['model_params']\n",
    "    ASR_model = ASRCNN(**ASR_model_config)\n",
    "    params = torch.load(ASR_path, map_location='cpu')['model']\n",
    "    ASR_model.load_state_dict(params)\n",
    "    _ = ASR_model.eval()    \n",
    "    \n",
    "    # load pretrained F0 model\n",
    "    F0_path = config.get('F0_path', False)\n",
    "    F0_model = JDCNet(num_class=1, seq_len=192)\n",
    "    params = torch.load(F0_path, map_location='cpu')['net']\n",
    "    F0_model.load_state_dict(params)\n",
    "    \n",
    "    # build model\n",
    "    model, model_ema = build_model(Munch(config['model_params']), F0_model, ASR_model)\n",
    "\n",
    "    scheduler_params = {\n",
    "        \"max_lr\": float(config['optimizer_params'].get('lr', 2e-4)),\n",
    "        \"pct_start\": float(config['optimizer_params'].get('pct_start', 0.0)),\n",
    "        \"epochs\": epochs,\n",
    "        \"steps_per_epoch\": len(train_dataloader),\n",
    "    }\n",
    "    \n",
    "    _ = [model[key].to(device) for key in model]\n",
    "    _ = [model_ema[key].to(device) for key in model_ema]\n",
    "    scheduler_params_dict = {key: scheduler_params.copy() for key in model}\n",
    "    optimizer = build_optimizer({key: model[key].parameters() for key in model},\n",
    "                                      scheduler_params_dict=scheduler_params_dict)\n",
    "\n",
    "    trainer = Trainer(args=Munch(config['loss_params']), model=model,\n",
    "                            model_ema=model_ema,\n",
    "                            optimizer=optimizer,\n",
    "                            device=device,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            val_dataloader=val_dataloader,\n",
    "                            logger=logger,\n",
    "                            fp16_run=fp16_run)\n",
    "\n",
    "    if config.get('pretrained_model', '') != '':\n",
    "        trainer.load_checkpoint(config['pretrained_model'],\n",
    "                                load_only_params=config.get('load_only_params', True))\n",
    "\n",
    "    for _ in range(1, epochs+1):\n",
    "        epoch = trainer.epochs\n",
    "        train_results = trainer._train_epoch()\n",
    "        eval_results = trainer._eval_epoch()\n",
    "        results = train_results.copy()\n",
    "        results.update(eval_results)\n",
    "        logger.info('--- epoch %d ---' % epoch)\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, float):\n",
    "                logger.info('%-15s: %.4f' % (key, value))\n",
    "                writer.add_scalar(key, value, epoch)\n",
    "            else:\n",
    "                for v in value:\n",
    "                    writer.add_figure('eval_spec', v, epoch)\n",
    "        if (epoch % save_freq) == 0:\n",
    "            trainer.save_checkpoint(osp.join(log_dir, 'epoch_%05d.pth' % epoch))\n",
    "    return 0\n",
    "\n",
    "main(\"Configs/config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
